





import numpy as np
from scipy import optimize
import matplotlib.pyplot as plt
%matplotlib inline
data_filename = "Example3_Data.txt"
using_colab = False


if using_colab:
  from google.colab import files
  uploaded = files.upload()
  data_filename = next(iter(uploaded.keys()))
  # This last line is a trick that will automatically pull the filename from what you uploaded.





print(open(data_filename).read())
t, A, dA = np.loadtxt(data_filename, unpack=True, skiprows=1)


fig, ax = plt.subplots(figsize = (10,8))
ax.errorbar(t, A, dA)
print(A)





def linear(p, xvar):
    return p[0] + p[1]*xvar

def residual(p,func, xvar, yvar, err):
    return (func(p, xvar) - yvar)/err


# The code below defines our data fitting function.
# Inputs are:
# initial guess for parameters p0
# the function we're fitting to
# the x,y, and dy variables
# tmi can be set to 1 or 2 if more intermediate data is needed

def data_fit(p0,func,xvar, yvar, err,tmi=0):
    try:
        fit = optimize.least_squares(residual, p0, args=(func,xvar, yvar, err),verbose=tmi)
    except Exception as error:
        print("Something has gone wrong:",error)
        return p0, np.full_like(p0,np.nan), np.nan, np.nan
    pf = fit['x']

    print()

    try:
        cov = np.linalg.inv(fit['jac'].T.dot(fit['jac']))          
        # This computes a covariance matrix by finding the inverse of the Jacobian times its transpose
        # We need this to find the uncertainty in our fit parameters
    except:
        # If the fit failed, print the reason
        print('Fit did not converge')
        print('Result is likely a local minimum')
        print('Try changing initial values')
        print('Status code:', fit['status'])
        print(fit['message'])
        return pf,np.full_like(p0,np.nan), np.nan, np.nan
            #You'll be able to plot with this, but it will not be a good fit.

    chisq = sum(residual(pf,func,xvar, yvar, err) **2)
    dof = len(xvar) - len(pf)
    red_chisq = chisq/dof
    pferr = np.sqrt(np.diagonal(cov)) # finds the uncertainty in fit parameters by squaring diagonal elements of the covariance matrix
    print('Converged with chi-squared {:.2f}'.format(chisq))
    print('Number of degrees of freedom, dof = {:.2f}'.format(dof))
    print('Reduced chi-squared {:.2f}'.format(red_chisq))
    print()
    Columns = ["Parameter #","Initial guess values:", "Best fit values:", "Uncertainties in the best fit values:"]
    print('{:<11}'.format(Columns[0]),'|','{:<24}'.format(Columns[1]),"|",'{:<24}'.format(Columns[2]),"|",'{:<24}'.format(Columns[3]))
    for num in range(len(pf)):
        print('{:<11}'.format(num),'|','{:<24.3e}'.format(p0[num]),'|','{:<24.3e}'.format(pf[num]),'|','{:<24.3e}'.format(pferr[num]))
    return pf, pferr, chisq, dof


print("Linear Fit")
guess = [10., 10.]
pf, pferr, chisq, dof = data_fit(guess,linear, t, A, dA)


fig, ax = plt.subplots(figsize = (10,8))
ax.errorbar(t, A, dA, fmt='k.', label = "Data")
t_cont = np.linspace(min(t), max(t), 200) 
  # This makes it so we get a smooth plot rather than only the function evaluated exactly at our data points
  # It isn't strictly needed for a straight line, but it will make other functions look much nicer
ax.plot(t_cont, linear(pf, t_cont), label = "Linear fit")
ax.legend()








def quadratic(p, xvar):
    return p[0] + p[1] * xvar + p[2] * (xvar ** 2)


print("Quadratic Fit")
quad_guess = [1, 1, 1]
quad_pf, quad_pferr, quad_chisq, quad_dof = data_fit(quad_guess, quadratic, t, A, dA)


fig, ax = plt.subplots(figsize = (10,8))
ax.errorbar(t, A, dA, fmt='k.', label = "Data")
t_cont = np.linspace(min(t), max(t), 200) 
  # This makes it so we get a smooth plot rather than only the function evaluated exactly at our data points
  # It isn't strictly needed for a straight line, but it will make other functions look much nicer
ax.plot(t_cont, quadratic(quad_pf, t_cont), label = "Quadratic fit")
ax.legend()





def expfunc(p, x):
    return p[0] * np.exp(-x * p[1])





guess_exp = [10, 1]
pf_exp, pferr_exp, chisq_exp, dof_exp = data_fit(guess_exp, expfunc, t, A, dA) 

fig, ax = plt.subplots(figsize = (10,8))
ax.errorbar(t, A, dA, fmt='k.', label = "Data")
t_cont = np.linspace(min(t), max(t), 200)
ax.plot(t_cont, linear(pf, t_cont), label = "Linear fit: $\\chi^2/N = {:0.2f}$".format(chisq/dof))
ax.plot(t_cont, expfunc(pf_exp, t_cont), label = "Exponential fit: $\\chi^2/N = {:0.2f}$".format(chisq_exp/dof_exp))
ax.legend()





data_fit(guess_exp, expfunc, t, A, dA) 


guess_exp = [10, 1]
pf_exp, pferr_exp, chisq_exp, dof_exp = data_fit(guess_exp, expfunc, t, A, dA) 

fig, ax = plt.subplots(figsize = (10,8))
ax.errorbar(t, A, dA, fmt='k.', label = "Data")
t_cont = np.linspace(min(t), max(t), 200)
ax.plot(t_cont, linear(pf, t_cont), label = "Linear fit: $\\chi^2/N = {:0.2f}$".format(chisq/dof))
ax.plot(t_cont, expfunc(pf_exp, t_cont), label = "Exponential fit: $\\chi^2/N = {:0.2f}$".format(chisq_exp/dof_exp))
ax.plot(t_cont, expfunc(guess_exp, t_cont), label = "Exponential fit guess")
ax.legend()








guess_exp = [100, 0.01]
pf_exp, pferr_exp, chisq_exp, dof_exp = data_fit(guess_exp, expfunc, t, A, dA) 

fig, ax = plt.subplots(figsize = (10,8))
ax.errorbar(t, A, dA, fmt='k.', label = "Data")
t_cont = np.linspace(min(t), max(t), 200)
ax.plot(t_cont, linear(pf,t_cont), label = "Linear fit: $\\chi^2/N = {:0.2f}$".format(chisq/dof))
ax.plot(t_cont, expfunc(pf_exp, t_cont), label = "Exponential fit: $\\chi^2/N = {:0.2f}$".format(chisq_exp/dof_exp))
ax.plot(t_cont, expfunc(guess_exp, t_cont), label = "Exponential fit guess")
ax.legend()





def expfunc_bg(p, x):
    return (p[0]*np.exp(-x*p[1])) + p[2]

#def expfunc_bg(p, x):
#    return expfunc([p[0],p[1]],x) + p[2]
# This is an alternate way you could define the background function by re-using the exponential function we already created.

guess_exp_bg = [100, .10, -0]
guess_exp = [100, .010]
pf_exp_bg, pferr_exp_bg, chisq_exp_bg, dof_exp_bg = data_fit(guess_exp_bg, expfunc_bg, t, A, dA) 
pf_exp, pferr_exp, chisq_exp, dof_exp = data_fit(guess_exp, expfunc, t, A, dA) 

fig, ax = plt.subplots(figsize = (10,8))
ax.errorbar(t, A, dA, fmt='k.', label = "Data")
t_cont = np.linspace(min(t), max(t), 200)
ax.plot(t_cont, linear(pf, t_cont), label = "Linear fit: $\\chi^2/N = {:0.2f}$".format(chisq/dof))
ax.plot(t_cont, expfunc(pf_exp, t_cont), label = "Exponential fit: $\\chi^2/N = {:0.2f}$".format(chisq_exp/dof_exp))
ax.plot(t_cont, expfunc_bg(pf_exp_bg, t_cont), label = "Exponential fit with background: $\\chi^2/N = {:0.2f}$".format(chisq_exp_bg/dof_exp_bg))
ax.legend()














your_filename = "mydata.txt"

if using_colab:
  from google.colab import files
  uploaded = files.upload()
  your_filename = next(iter(uploaded.keys()))
  # This last line is a trick that will automatically pull the filename from what you uploaded.

print(open(your_filename).read())
x, dx, t, G1, N1, G2, N2 = np.loadtxt(your_filename, unpack=True, skiprows=1)
print(x)











R1 = G1 / t
R2 = G2 / t

print(R1)
print(R2)









dR1 = R1 * np.sqrt(G1) / G1
dR2 = R2 * np.sqrt(G2) / G2

print(dR1)
print(dR2)





guess_exp_bg = [100, .10, -0]

fig, (ax0, ax1) = plt.subplots(1, 2, figsize = (16,6))

x_cont = np.linspace(min(x), max(x), 200)

my_exp_pf, my_exp_pferr, my_exp_chisq, my_exp_dof = data_fit(guess_exp_bg, expfunc_bg, x, R1, dR1) 

ax0.errorbar(x, R1, dR1, fmt='k.', label = "Data")
ax0.plot(x_cont, expfunc_bg(my_exp_pf, x_cont), color='r', label = "Fit")
txt = '$R(x)=R_0 e^{-\\lambda x} + B$ \n' 
txt += '$R_0 = {:.2f} \\pm {:.2f}$ \n'.format(my_exp_pf[0], my_exp_pferr[0]) 
txt += '$\\lambda = {:.2f} \\pm {:.2f}$ \n'.format(my_exp_pf[1], my_exp_pferr[1]) 
txt += '$B = {:.2f} \\pm {:.2f}$ \n'.format(my_exp_pf[2], my_exp_pferr[2]) 
txt += '$\\chi^2= {:.1f}$ \n'.format(my_exp_chisq) 
txt += '$N = {}$ (dof) \n'.format(my_exp_dof) 
txt += '$\\chi^2/N = {:.2f}$'.format(my_exp_chisq/my_exp_dof) 
ax0.text(0.5, 0.8, txt, transform=ax0.transAxes , fontsize=12, verticalalignment='top')
ax0.set_title('Peak 1 Rate')
ax0.legend()

my_exp_pf, my_exp_pferr, my_exp_chisq, my_exp_dof = data_fit(guess_exp_bg, expfunc_bg, x, R2, dR2) 

ax1.errorbar(x, R2, dR2, fmt='k.', label = "Data")
ax1.plot(x_cont, expfunc_bg(my_exp_pf, x_cont), color='r', label = "Fit")
txt = '$R(x)=R_0 e^{-\\lambda x} + B$ \n' 
txt += '$R_0 = {:.2f} \\pm {:.2f}$ \n'.format(my_exp_pf[0], my_exp_pferr[0]) 
txt += '$\\lambda = {:.2f} \\pm {:.2f}$ \n'.format(my_exp_pf[1], my_exp_pferr[1]) 
txt += '$B = {:.2f} \\pm {:.2f}$ \n'.format(my_exp_pf[2], my_exp_pferr[2]) 
txt += '$\\chi^2= {:.1f}$ \n'.format(my_exp_chisq) 
txt += '$N = {}$ (dof) \n'.format(my_exp_dof) 
txt += '$\\chi^2/N = {:.2f}$'.format(my_exp_chisq/my_exp_dof) 
ax1.text(0.5, 0.8, txt, transform=ax1.transAxes , fontsize=12, verticalalignment='top')
ax1.set_title('Peak 2 Rate')
ax1.legend()

fig.suptitle('Fitted Rates for Two Peaks', fontsize=24)
plt.tight_layout()

plt.savefig('task6.pdf')











guess_exp_bg = [100, .10, -10]
pf_exp_bg, pferr_exp_bg, chisq_exp_bg, dof_exp_bg = data_fit(guess_exp_bg, expfunc_bg, x, R1, dR1) 
pf_exp_bg1, pferr_exp_bg1, chisq_exp_bg1, dof_exp_bg1 = data_fit(guess_exp_bg, expfunc_bg, x, R2, dR2) 

fig, ax = plt.subplots(figsize = (8,6))
ax.errorbar(x, R1, dR1, fmt='k.', label = "511 keV Data",capsize=3)
ax.errorbar(x, R2, dR2, fmt='g.', label = "1.28 MeV Data",capsize=3)

x_cont = np.linspace(min(x), max(x), 200)
ax.plot(x_cont, expfunc_bg(pf_exp_bg, x_cont), label = "$\\lambda = {:.4f} cm^{{-1}}$".format(pf_exp_bg[1]))
ax.plot(x_cont, expfunc_bg(pf_exp_bg1, x_cont), label = "$\\lambda = {:.4f} cm^{{-1}}$".format(pf_exp_bg1[1]))
ax.set_ylabel("Count Rate, R(counts/s)", fontsize=16)
ax.set_xlabel("Thickness, x(cm)", fontsize=16)
ax.set_title("Aluminum, Na22 Source", fontsize=20)
fig.suptitle("$\\gamma$ Transmisson Intensity", fontsize=20)

ax.xaxis.set_tick_params(labelsize=14)
ax.yaxis.set_tick_params(labelsize=14)
ax.set_ylim(10,1000)
ax.set_yscale("log")
ax.legend(fontsize=14)
plt.tight_layout()






guess_exp_bg = [100, .10, -10]
pf_exp_bg, pferr_exp_bg, chisq_exp_bg, dof_exp_bg = data_fit(guess_exp_bg, expfunc_bg, x, R1, dR1) 

fig, ax = plt.subplots(figsize = (8,6))

difference = R1-expfunc_bg(pf_exp_bg, x)
within_one_sigma = (np.abs(difference/dR1)>0) * (np.abs(difference/dR1)<1)
# The above creates a list of all the places where the difference between our fit and the data is less than 1 times the uncertainty for the measurement.
one_to_two_sigma = (np.abs(difference/dR1)>1) * (np.abs(difference/dR1)<2)
two_to_three_sigma = (np.abs(difference/dR1)>2) * (np.abs(difference/dR1)<3)
ax.errorbar(x[within_one_sigma],difference[within_one_sigma], dR1[within_one_sigma], fmt='g.', label = "0-1 sigma",capsize=5,markersize=12)
ax.errorbar(x[one_to_two_sigma],difference[one_to_two_sigma ], dR1[one_to_two_sigma ], fmt='b.', label = "1-2 sigma",capsize=5,markersize=12)
ax.errorbar(x[two_to_three_sigma], difference[two_to_three_sigma], dR1[two_to_three_sigma], fmt='k.', label = "2-3 sigma",capsize=5,markersize=12)

ax.set_ylabel("Difference in Count Rate, R(counts/s)", fontsize=16)
ax.set_xlabel("Thickness, x(cm)", fontsize=16)
ax.set_title("Deviations in 511 KeV fit", fontsize=20)
ax.axhline(0)

ax.xaxis.set_tick_params(labelsize=14)
ax.yaxis.set_tick_params(labelsize=14)
ax.legend(fontsize=14)
plt.tight_layout()




